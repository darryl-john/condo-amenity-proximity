{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd521565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import time, random, requests, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1505291",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "\n",
    "# Set headers for the session\n",
    "s.headers.update({\n",
    "   \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                 \"(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n",
    "   \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "   \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "})\n",
    "\n",
    "# Function to fetch a URL with retries\n",
    "def fetch(url, max_tries=10):\n",
    "   delay = 3.0\n",
    "   for i in range(max_tries):\n",
    "       r = s.get(url, timeout=45)\n",
    "       if r.status_code in (200, 304):\n",
    "           # polite delay between successful fetches\n",
    "           time.sleep(delay + random.random()*2)\n",
    "           return r\n",
    "       if r.status_code in (429, 503):  # too many / temporarily blocked\n",
    "           time.sleep(delay)\n",
    "           delay *= 2\n",
    "           continue\n",
    "       r.raise_for_status()\n",
    "   raise RuntimeError(f\"Failed after {max_tries} tries: {url}\")\n",
    "\n",
    "# Function to extract string from a BeautifulSoup object\n",
    "def get_text(object, tag, attributes, text=None):\n",
    "    try:\n",
    "        return object.find(tag, attrs=attributes, text=text).string.strip()\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Function for error handling\n",
    "def maybe(function):\n",
    "    try:\n",
    "        return function()\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d63664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the listings\n",
    "list_url = \"https://www.dotproperty.com.ph/condos/all/metro-manila\"\n",
    "\n",
    "start_page = 1\n",
    "end_page = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or clear the output file\n",
    "with open('dotproperty-projects.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    pass\n",
    "\n",
    "results = []\n",
    "batch = []\n",
    "batch_size = 50\n",
    "\n",
    "# Fetch listings from the specified pages and write to file\n",
    "with open('dotproperty-projects.txt', 'a', encoding=\"utf-8\") as f:\n",
    "\n",
    "    for page in range(start_page, end_page + 1):\n",
    "        response = fetch(list_url + ((\"?page=\" + str(page)) if page > 1 else \"\" ))\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        listings = soup.find_all('article', attrs={\"class\": \"col-xs-6 projects-list projects-list-even\"})\n",
    "\n",
    "        for listing in listings:\n",
    "\n",
    "            response = fetch(listing.find('a', attrs={\"itemprop\": \"url\"}, href=True)['href'])\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "            project_name = get_text(soup, 'h1', {\"itemprop\": \"name\", \"class\": \"page-title\"})   \n",
    "            location = get_text(soup, 'div', {\"class\": \"view-on-map-info-location__text\"})\n",
    "\n",
    "            record = {\n",
    "                'project_name': project_name,\n",
    "                'location': location\n",
    "            }\n",
    "\n",
    "            # Convert record to JSON line\n",
    "            json_line = json.dumps(record, ensure_ascii=False)\n",
    "\n",
    "            # Add to results for DataFrame\n",
    "            results.append(record)\n",
    "\n",
    "            # Add to batch for file writing\n",
    "            batch.append(json_line)\n",
    "\n",
    "            # Save to file every batch_size items\n",
    "            if len(batch) == batch_size or page == end_page:\n",
    "                f.write('\\n'.join(batch) + '\\n')\n",
    "                batch = []\n",
    "            \n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
